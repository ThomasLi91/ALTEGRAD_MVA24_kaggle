{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76OF5JYcF9UW"
      },
      "source": [
        "# üöÄ Install, Import, and Log In"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_Hi83U4F9UW"
      },
      "source": [
        "### 0Ô∏è‚É£ Step 0: Install W&B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAVVlF7OF9UX"
      },
      "source": [
        "To get started, we'll need to get the library.\n",
        "`wandb` is easily installed using `pip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf61j-SSF9UX",
        "outputId": "e14c09db-5188-48df-c35c-dfc8a1f347c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install wandb onnx -Uq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qu8tbbAxF9UZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Ensure deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
        "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
        "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
        "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# remove slow mirror from list of MNIST mirrors\n",
        "torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors\n",
        "                                      if not mirror.startswith(\"http://yann.lecun.com\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-aZVySiF9UZ"
      },
      "source": [
        "### 1Ô∏è‚É£ Step 1: Import W&B and Login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q4d6zLQF9UZ"
      },
      "source": [
        "In order to log data to our web service,\n",
        "you'll need to log in.\n",
        "\n",
        "If this is your first time using W&B,\n",
        "you'll need to sign up for a free account at the link that appears."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HbiEj3JFF9Ua"
      },
      "outputs": [],
      "source": [
        "import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "RnWzng-xF9Ua",
        "outputId": "096c5c26-5674-4dea-aa99-5cd88ceab1c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAQKoyn7F9Ua"
      },
      "source": [
        "# üë©‚Äçüî¨ Define the Experiment and Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW1WQU8TF9Ua"
      },
      "source": [
        "## 2Ô∏è‚É£ Step 2: Track metadata and hyperparameters with `wandb.init`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5xUzkTQF9Ua"
      },
      "source": [
        "Programmatically, the first thing we do is define our experiment:\n",
        "what are the hyperparameters? what metadata is associated with this run?\n",
        "\n",
        "It's a pretty common workflow to store this information in a `config` dictionary\n",
        "(or similar object)\n",
        "and then access it as needed.\n",
        "\n",
        "For this example, we're only letting a few hyperparameters vary\n",
        "and hand-coding the rest.\n",
        "But any part of your model can be part of the `config`!\n",
        "\n",
        "We also include some metadata: we're using the MNIST dataset and a convolutional\n",
        "architecture. If we later work with, say,\n",
        "fully-connected architectures on CIFAR in the same project,\n",
        "this will help us separate our runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Kf-6FHrsF9Ua"
      },
      "outputs": [],
      "source": [
        "config = dict(\n",
        "    epochs=5,\n",
        "    classes=10,\n",
        "    kernels=[16, 32],\n",
        "    batch_size=32,\n",
        "    learning_rate=0.1,\n",
        "    dataset=\"MNIST\",\n",
        "    architecture=\"CNN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSCjX5SYF9Ua"
      },
      "source": [
        "Now, let's define the overall pipeline,\n",
        "which is pretty typical for model-training:\n",
        "\n",
        "1. we first `make` a model, plus associated data and optimizer, then\n",
        "2. we `train` the model accordingly and finally\n",
        "3. `test` it to see how training went.\n",
        "\n",
        "We'll implement these functions below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EJd5rY4fF9Ub"
      },
      "outputs": [],
      "source": [
        "PROJECT_NAME = \"pytorch-demo\"\n",
        "\n",
        "def model_pipeline(hyperparameters, run_name = None):\n",
        "\n",
        "    # tell wandb to get started\n",
        "    with wandb.init(project=PROJECT_NAME, config=hyperparameters, name = run_name):\n",
        "      # access all HPs through wandb.config, so logging matches execution!\n",
        "      config = wandb.config\n",
        "\n",
        "      # make the model, data, and optimization problem\n",
        "      model, train_loader, test_loader, criterion, optimizer = make(config)\n",
        "      print(model)\n",
        "\n",
        "      # and use them to train the model\n",
        "      train(model, train_loader, criterion, optimizer, config)\n",
        "\n",
        "      # and test its final performance\n",
        "      test(model, test_loader)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTi7f9V3F9Ub"
      },
      "source": [
        "The only difference here from a standard pipeline\n",
        "is that it all occurs inside the context of `wandb.init`.\n",
        "Calling this function sets up a line of communication\n",
        "between your code and our servers.\n",
        "\n",
        "Passing the `config` dictionary to `wandb.init`\n",
        "immediately logs all that information to us,\n",
        "so you'll always know what hyperparameter values\n",
        "you set your experiment to use.\n",
        "\n",
        "To ensure the values you chose and logged are always the ones that get used\n",
        "in your model, we recommend using the `wandb.config` copy of your object.\n",
        "Check the definition of `make` below to see some examples.\n",
        "\n",
        "> *Side Note*: We take care to run our code in separate processes,\n",
        "so that any issues on our end\n",
        "(e.g. a giant sea monster attacks our data centers)\n",
        "don't crash your code.\n",
        "Once the issue is resolved (e.g. the Kraken returns to the deep)\n",
        "you can log the data with `wandb sync`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ArUb9hoKF9Ub"
      },
      "outputs": [],
      "source": [
        "def make(config):\n",
        "    # Make the data\n",
        "    train, test = get_data(train=True), get_data(train=False)\n",
        "    train_loader = make_loader(train, batch_size=config.batch_size)\n",
        "    test_loader = make_loader(test, batch_size=config.batch_size)\n",
        "\n",
        "    # Make the model\n",
        "    model = ConvNet(config.kernels, config.classes).to(device)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    return model, train_loader, test_loader, criterion, optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZWcIkISF9Ub"
      },
      "source": [
        "# üì° Define the Data Loading and Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO8jpAuHF9Ub"
      },
      "source": [
        "Now, we need to specify how the data is loaded and what the model looks like.\n",
        "\n",
        "This part is very important, but it's\n",
        "no different from what it would be without `wandb`,\n",
        "so we won't dwell on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VjpNyhCeF9Ub"
      },
      "outputs": [],
      "source": [
        "def get_data(slice=5, train=True):\n",
        "    full_dataset = torchvision.datasets.MNIST(root=\".\",\n",
        "                                              train=train,\n",
        "                                              transform=transforms.ToTensor(),\n",
        "                                              download=True)\n",
        "    #  equiv to slicing with [::slice]\n",
        "    sub_dataset = torch.utils.data.Subset(\n",
        "      full_dataset, indices=range(0, len(full_dataset), slice))\n",
        "\n",
        "    return sub_dataset\n",
        "\n",
        "\n",
        "def make_loader(dataset, batch_size):\n",
        "    loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True,\n",
        "                                         pin_memory=True, num_workers=2)\n",
        "    return loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk6l5PO4F9Ub"
      },
      "source": [
        "Defining the model is normally the fun part!\n",
        "\n",
        "But nothing changes with `wandb`,\n",
        "so we're gonna stick with a standard ConvNet architecture.\n",
        "\n",
        "Don't be afraid to mess around with this and try some experiments --\n",
        "all your results will be logged on [wandb.ai](https://wandb.ai)!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EmHIL29EF9Uc"
      },
      "outputs": [],
      "source": [
        "# Conventional and convolutional neural network\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, kernels, classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, kernels[1], kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7 * 7 * kernels[-1], classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM41L4KjF9Uc"
      },
      "source": [
        "# üëü Define Training Logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWHnwq-vF9Uc"
      },
      "source": [
        "Moving on in our `model_pipeline`, it's time to specify how we `train`.\n",
        "\n",
        "Two `wandb` functions come into play here: `watch` and `log`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECLQb5Q6F9Uc"
      },
      "source": [
        "### 3Ô∏è‚É£ Step 3. Track gradients with `wandb.watch` and everything else with `wandb.log`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHoc9_kyF9Uc"
      },
      "source": [
        "`wandb.watch` will log the gradients and the parameters of your model,\n",
        "every `log_freq` steps of training.\n",
        "\n",
        "All you need to do is call it before you start training.\n",
        "\n",
        "The rest of the training code remains the same:\n",
        "we iterate over epochs and batches,\n",
        "running forward and backward passes\n",
        "and applying our `optimizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fZ4RrRKmF9Uc"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, criterion, optimizer, config):\n",
        "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    # Run training and track with wandb\n",
        "    total_batches = len(loader) * config.epochs\n",
        "    example_ct = 0  # number of examples seen\n",
        "    batch_ct = 0\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "        for _, (images, labels) in enumerate(loader):\n",
        "\n",
        "            loss = train_batch(images, labels, model, optimizer, criterion)\n",
        "            example_ct +=  len(images)\n",
        "            batch_ct += 1\n",
        "\n",
        "            # Report metrics every 25th batch\n",
        "            if ((batch_ct + 1) % 25) == 0:\n",
        "                train_log(loss, example_ct, epoch)\n",
        "\n",
        "\n",
        "def train_batch(images, labels, model, optimizer, criterion):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Forward pass ‚û°\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass ‚¨Ö\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Step with optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiO9SPHpF9Ud"
      },
      "source": [
        "The only difference is in the logging code:\n",
        "where previously you might have reported metrics by printing to the terminal,\n",
        "now you pass the same information to `wandb.log`.\n",
        "\n",
        "`wandb.log` expects a dictionary with strings as keys.\n",
        "These strings identify the objects being logged, which make up the values.\n",
        "You can also optionally log which `step` of training you're on.\n",
        "\n",
        "> *Side Note*: I like to use the number of examples the model has seen,\n",
        "since this makes for easier comparison across batch sizes,\n",
        "but you can use raw steps or batch count. For longer training runs, it can also make sense to log by `epoch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SDS3C29GF9Ud"
      },
      "outputs": [],
      "source": [
        "def train_log(loss, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEU-Yu2nF9Ud"
      },
      "source": [
        "# üß™ Define Testing Logic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IyIocpbF9Ud"
      },
      "source": [
        "Once the model is done training, we want to test it:\n",
        "run it against some fresh data from production, perhaps,\n",
        "or apply it to some hand-curated \"hard examples\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlRGjS7IF9Ue"
      },
      "source": [
        "#### 4Ô∏è‚É£ Optional Step 4: Call `wandb.save`\n",
        "\n",
        "This is also a great time to save the model's architecture\n",
        "and final parameters to disk.\n",
        "For maximum compatibility, we'll `export` our model in the\n",
        "[Open Neural Network eXchange (ONNX) format](https://onnx.ai/).\n",
        "\n",
        "Passing that filename to `wandb.save` ensures that the model parameters\n",
        "are saved to W&B's servers: no more losing track of which `.h5` or `.pb`\n",
        "corresponds to which training runs!\n",
        "\n",
        "For more advanced `wandb` features for storing, versioning, and distributing\n",
        "models, check out our [Artifacts tools](https://www.wandb.com/artifacts)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8xs8SNEdF9Ue"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        correct, total = 0, 0\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f\"Accuracy of the model on the {total} \" +\n",
        "              f\"test images: {correct / total:%}\")\n",
        "\n",
        "        wandb.log({\"test_accuracy\": correct / total})\n",
        "\n",
        "    # Save the model in the exchangeable ONNX format\n",
        "    torch.onnx.export(model, images, \"model.onnx\")\n",
        "    wandb.save(\"model.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGttC0nnF9Uk"
      },
      "source": [
        "# üèÉ‚Äç‚ôÄÔ∏è Run training and watch your metrics live on wandb.ai!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChGTEiqBF9Uk"
      },
      "source": [
        "Now that we've defined the whole pipeline and slipped in\n",
        "those few lines of W&B code,\n",
        "we're ready to run our fully-tracked experiment.\n",
        "\n",
        "We'll report a few links to you:\n",
        "our documentation,\n",
        "the Project page, which organizes all the runs in a project, and\n",
        "the Run page, where this run's results will be stored.\n",
        "\n",
        "Navigate to the Run page and check out these tabs:\n",
        "\n",
        "1. **Charts**, where the model gradients, parameter values, and loss are logged throughout training\n",
        "2. **System**, which contains a variety of system metrics, including Disk I/O utilization, CPU and GPU metrics (watch that temperature soar üî•), and more\n",
        "3. **Logs**, which has a copy of anything pushed to standard out during training\n",
        "4. **Files**, where, once training is complete, you can click on the `model.onnx` to view our network with the [Netron model viewer](https://github.com/lutzroeder/netron).\n",
        "\n",
        "Once the run in finished\n",
        "(i.e. the `with wandb.init` block is exited),\n",
        "we'll also print a summary of the results in the cell output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "686efbf4ab4b467ea1139b9cc74f7677",
            "a0c1158993d34974889b469fb0443010",
            "64fd6859505845b6b06c0834e9b6acf6",
            "983af58ac73d4e98a133e27a84ca9dee",
            "259a994512cc4b72b97ff5f4f08f2bf8",
            "fd8d3bcabd3942d2ad05dee10b51274b",
            "2527e908037741e0b2750fa50d83467d",
            "92cbb8039ee64e5f9fdbc6b35e4bca52",
            "8f1834e94d6d4495b1de7d832ed8bc16",
            "a54b36f5b46148f8ac06f7a50865c1ee",
            "b17c1cc7ecf24d078ecc805fd01f8431",
            "85382ff43bd14c8fbd6afedfef4128e1",
            "e4eeb4edafef436aa59b0b7fa57bfcf7",
            "1548877d82e1467a8ea031ae001a8210",
            "d1c8407500b64c799ea6344723d9e2f0",
            "869359f394bf4aebacfb18699b889473",
            "dfb278d9d72e4a9995bb7ac35edd4224",
            "2b4043b3364941f4af8a9bc08447f9e3",
            "200a2c47ff6244c4b087eaf4380c0294"
          ]
        },
        "id": "LO-kom5AF9Uk",
        "outputId": "c7db0742-0fed-4a21-fba7-1113f2760466"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240126_143037-g0v51bau</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/qwertyr2/pytorch-demo/runs/g0v51bau' target=\"_blank\">chien1</a></strong> to <a href='https://wandb.ai/qwertyr2/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/qwertyr2/pytorch-demo' target=\"_blank\">https://wandb.ai/qwertyr2/pytorch-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/qwertyr2/pytorch-demo/runs/g0v51bau' target=\"_blank\">https://wandb.ai/qwertyr2/pytorch-demo/runs/g0v51bau</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "686efbf4ab4b467ea1139b9cc74f7677"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after 00768 examples: 1.972\n",
            "Loss after 01568 examples: 0.896\n",
            "Loss after 02368 examples: 0.666\n",
            "Loss after 03168 examples: 0.696\n",
            "Loss after 03968 examples: 0.481\n",
            "Loss after 04768 examples: 0.304\n",
            "Loss after 05568 examples: 0.793\n",
            "Loss after 06368 examples: 0.485\n",
            "Loss after 07168 examples: 0.648\n",
            "Loss after 07968 examples: 0.588\n",
            "Loss after 08768 examples: 0.321\n",
            "Loss after 09568 examples: 1.066\n",
            "Loss after 10368 examples: 0.650\n",
            "Loss after 11168 examples: 0.654\n",
            "Loss after 11968 examples: 1.563\n",
            "Loss after 12768 examples: 0.585\n",
            "Loss after 13568 examples: 0.270\n",
            "Loss after 14368 examples: 0.664\n",
            "Loss after 15168 examples: 0.694\n",
            "Loss after 15968 examples: 0.308\n",
            "Loss after 16768 examples: 0.952\n",
            "Loss after 17568 examples: 0.554\n",
            "Loss after 18368 examples: 1.318\n",
            "Loss after 19168 examples: 0.319\n",
            "Loss after 19968 examples: 0.454\n",
            "Loss after 20768 examples: 0.660\n",
            "Loss after 21568 examples: 0.282\n",
            "Loss after 22368 examples: 0.581\n",
            "Loss after 23168 examples: 1.361\n",
            "Loss after 23968 examples: 1.209\n",
            "Loss after 24768 examples: 0.570\n",
            "Loss after 25568 examples: 0.391\n",
            "Loss after 26368 examples: 0.764\n",
            "Loss after 27168 examples: 0.956\n",
            "Loss after 27968 examples: 1.138\n",
            "Loss after 28768 examples: 0.922\n",
            "Loss after 29568 examples: 0.909\n",
            "Loss after 30368 examples: 0.528\n",
            "Loss after 31168 examples: 0.183\n",
            "Loss after 31968 examples: 0.425\n",
            "Loss after 32768 examples: 0.633\n",
            "Loss after 33568 examples: 0.770\n",
            "Loss after 34368 examples: 0.652\n",
            "Loss after 35168 examples: 0.367\n",
            "Loss after 35968 examples: 0.514\n",
            "Loss after 36768 examples: 0.535\n",
            "Loss after 37568 examples: 0.448\n",
            "Loss after 38368 examples: 1.180\n",
            "Loss after 39168 examples: 0.662\n",
            "Loss after 39968 examples: 1.122\n",
            "Loss after 40768 examples: 0.281\n",
            "Loss after 41568 examples: 0.850\n",
            "Loss after 42368 examples: 0.534\n",
            "Loss after 43168 examples: 1.145\n",
            "Loss after 43968 examples: 0.339\n",
            "Loss after 44768 examples: 0.515\n",
            "Loss after 45568 examples: 1.094\n",
            "Loss after 46368 examples: 0.433\n",
            "Loss after 47168 examples: 0.387\n",
            "Loss after 47968 examples: 0.444\n",
            "Loss after 48768 examples: 1.159\n",
            "Loss after 49568 examples: 1.512\n",
            "Loss after 50368 examples: 1.218\n",
            "Loss after 51168 examples: 0.770\n",
            "Loss after 51968 examples: 1.122\n",
            "Loss after 52768 examples: 0.868\n",
            "Loss after 53568 examples: 0.827\n",
            "Loss after 54368 examples: 0.810\n",
            "Loss after 55168 examples: 0.205\n",
            "Loss after 55968 examples: 0.956\n",
            "Loss after 56768 examples: 0.953\n",
            "Loss after 57568 examples: 0.885\n",
            "Loss after 58368 examples: 0.984\n",
            "Loss after 59168 examples: 0.818\n",
            "Loss after 59968 examples: 0.743\n",
            "Accuracy of the model on the 2000 test images: 74.350000%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.113 MB of 0.113 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85382ff43bd14c8fbd6afedfef4128e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>loss</td><td>‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÉ</td></tr><tr><td>test_accuracy</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.74326</td></tr><tr><td>test_accuracy</td><td>0.7435</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">chien1</strong> at: <a href='https://wandb.ai/qwertyr2/pytorch-demo/runs/g0v51bau' target=\"_blank\">https://wandb.ai/qwertyr2/pytorch-demo/runs/g0v51bau</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240126_143037-g0v51bau/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Build, train and analyze the model with the pipeline\n",
        "model = model_pipeline(config, run_name = \"chien1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrGF9EKCF9Uk"
      },
      "source": [
        "# üßπ Test Hyperparameters with Sweeps\n",
        "\n",
        "We only looked at a single set of hyperparameters in this example.\n",
        "But an important part of most ML workflows is iterating over\n",
        "a number of hyperparameters.\n",
        "\n",
        "You can use Weights & Biases Sweeps to automate hyperparameter testing and explore the space of possible models and optimization strategies.\n",
        "\n",
        "## [Check out Hyperparameter Optimization in PyTorch using W&B Sweeps $\\rightarrow$](http://wandb.me/sweeps-colab)\n",
        "\n",
        "Running a hyperparameter sweep with Weights & Biases is very easy. There are just 3 simple steps:\n",
        "\n",
        "1. **Define the sweep:** We do this by creating a dictionary or a [YAML file](https://docs.wandb.com/library/sweeps/configuration) that specifies the parameters to search through, the search strategy, the optimization metric et all.\n",
        "\n",
        "2. **Initialize the sweep:**\n",
        "`sweep_id = wandb.sweep(sweep_config)`\n",
        "\n",
        "3. **Run the sweep agent:**\n",
        "`wandb.agent(sweep_id, function=train)`\n",
        "\n",
        "And voila! That's all there is to running a hyperparameter sweep!\n",
        "<img src=\"https://imgur.com/UiQKg0L.png\" alt=\"Weights & Biases\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiia-E_XF9Uk"
      },
      "source": [
        "# üñºÔ∏è Example Gallery\n",
        "\n",
        "See examples of projects tracked and visualized with W&B in our [Gallery ‚Üí](https://app.wandb.ai/gallery)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeqzFBkkF9Ul"
      },
      "source": [
        "# ü§ì Advanced Setup\n",
        "1. [Environment variables](https://docs.wandb.com/library/environment-variables): Set API keys in environment variables so you can run training on a managed cluster.\n",
        "2. [Offline mode](https://docs.wandb.com/library/technical-faq#can-i-run-wandb-offline): Use `dryrun` mode to train offline and sync results later.\n",
        "3. [On-prem](https://docs.wandb.com/self-hosted): Install W&B in a private cloud or air-gapped servers in your own infrastructure. We have local installations for everyone from academics to enterprise teams.\n",
        "4. [Sweeps](https://docs.wandb.com/sweeps): Set up hyperparameter search quickly with our lightweight tool for tuning."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "686efbf4ab4b467ea1139b9cc74f7677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0c1158993d34974889b469fb0443010",
              "IPY_MODEL_64fd6859505845b6b06c0834e9b6acf6",
              "IPY_MODEL_983af58ac73d4e98a133e27a84ca9dee"
            ],
            "layout": "IPY_MODEL_259a994512cc4b72b97ff5f4f08f2bf8"
          }
        },
        "a0c1158993d34974889b469fb0443010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8d3bcabd3942d2ad05dee10b51274b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2527e908037741e0b2750fa50d83467d",
            "value": "100%"
          }
        },
        "64fd6859505845b6b06c0834e9b6acf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92cbb8039ee64e5f9fdbc6b35e4bca52",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f1834e94d6d4495b1de7d832ed8bc16",
            "value": 5
          }
        },
        "983af58ac73d4e98a133e27a84ca9dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a54b36f5b46148f8ac06f7a50865c1ee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b17c1cc7ecf24d078ecc805fd01f8431",
            "value": " 5/5 [00:15&lt;00:00,  3.11s/it]"
          }
        },
        "259a994512cc4b72b97ff5f4f08f2bf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8d3bcabd3942d2ad05dee10b51274b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2527e908037741e0b2750fa50d83467d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92cbb8039ee64e5f9fdbc6b35e4bca52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f1834e94d6d4495b1de7d832ed8bc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a54b36f5b46148f8ac06f7a50865c1ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17c1cc7ecf24d078ecc805fd01f8431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85382ff43bd14c8fbd6afedfef4128e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4eeb4edafef436aa59b0b7fa57bfcf7",
              "IPY_MODEL_1548877d82e1467a8ea031ae001a8210"
            ],
            "layout": "IPY_MODEL_d1c8407500b64c799ea6344723d9e2f0"
          }
        },
        "e4eeb4edafef436aa59b0b7fa57bfcf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869359f394bf4aebacfb18699b889473",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dfb278d9d72e4a9995bb7ac35edd4224",
            "value": "0.146 MB of 0.146 MB uploaded\r"
          }
        },
        "1548877d82e1467a8ea031ae001a8210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b4043b3364941f4af8a9bc08447f9e3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_200a2c47ff6244c4b087eaf4380c0294",
            "value": 1
          }
        },
        "d1c8407500b64c799ea6344723d9e2f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "869359f394bf4aebacfb18699b889473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb278d9d72e4a9995bb7ac35edd4224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b4043b3364941f4af8a9bc08447f9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200a2c47ff6244c4b087eaf4380c0294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}